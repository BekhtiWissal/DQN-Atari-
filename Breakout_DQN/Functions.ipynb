{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(state):\n",
    "  state = np.array(state)\n",
    "  state = np.moveaxis(state,0,2)/255 #normalisation\n",
    "  state = np.expand_dims(state,0)\n",
    "  state = torch.from_numpy(state)\n",
    "  state = state.clone().detach().to(dtype=torch.float32, device=device).unsqueeze(0)\n",
    "  state = torch.permute(state, (0,1,4,3,2))\n",
    "  state = torch.squeeze(state)\n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame):\n",
    "    frame = frame[30:-12,5:-4]\n",
    "    frame = np.average(frame,axis = 2)\n",
    "    frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST)\n",
    "    frame = np.array(frame,dtype = np.uint8)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_network(policy_net, target_net, TAU):\n",
    "    target_net_state_dict = target_net.state_dict()\n",
    "    policy_net_state_dict = policy_net.state_dict()\n",
    "    for key in policy_net_state_dict:\n",
    "        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "    target_net.load_state_dict(target_net_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_explore(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    state = state.clone().detach().to(dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    eps_threshold = 0.1 + (1 - 0.1) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_exploit(state):\n",
    "    state = state.unsqueeze(0)\n",
    "    print(policy_net(state))\n",
    "    action = policy_net(state).max(1)[1].view(1, 1)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(scores, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
